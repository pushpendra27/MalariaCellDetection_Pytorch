{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#GPU_CUDA Details \n",
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.cudnn.enabled)\n",
    "print(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your transforms for the training, validation, and testing sets\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),transforms.RandomResizedCrop(224),transforms.RandomVerticalFlip(),transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(256),transforms.CenterCrop(224),transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "validation_transforms = transforms.Compose([transforms.Resize(256),transforms.CenterCrop(224),transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                                 [0.229, 0.224, 0.225])])\n",
    "img_dir='cell_images/';\n",
    "train_data = datasets.ImageFolder(img_dir,transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "test_size = 0.1\n",
    "# convert data to a normalized torch.FloatTensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "valid_split = int(np.floor((valid_size) * num_train))\n",
    "test_split = int(np.floor((valid_size+test_size) * num_train))\n",
    "valid_idx, test_idx, train_idx = indices[:valid_split], indices[valid_split:test_split], indices[test_split:]\n",
    "\n",
    "#print(len(valid_idx), len(test_idx), len(train_idx))\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64,\n",
    "    sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=32, \n",
    "    sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(train_data, batch_size=20, \n",
    "    sampler=test_sampler, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Linear(2048, 2, bias=True)\n",
    "\n",
    "fc_parameters = model.fc.parameters()\n",
    "\n",
    "for param in fc_parameters:\n",
    "    param.requires_grad = True\n",
    "    \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer & loss Func #loss_func = torch.nn.MSELoss()\n",
    "use_cuda=torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(model.fc.parameters(), lr=0.001 , momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer = torch.optim.Adam(net_Adam.parameters(), lr = LR, betas= (0.9, 0.99))\n",
    "#torch.optim.RMSprop(params, lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "#optimizer=torch.optim.RMSprop(model.parameters(), lr = LR, alpha = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import EarlyStopping\n",
    "from pytorchtool import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3636045202810243\n",
      "Valid_Loss: 0.4565687221771031\n",
      "Epoch: 1 \tTraining Loss: 0.363605 \tValidation Loss: 0.456569\n",
      "Validation loss decreased (inf --> 0.456569).  Saving model ...\n",
      "Train Loss: 0.3692916091901577\n",
      "Valid_Loss: 0.344699022139428\n",
      "Epoch: 2 \tTraining Loss: 0.369292 \tValidation Loss: 0.344699\n",
      "Validation loss decreased (0.456569 --> 0.344699).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "    patience=20\n",
    "    n_epochs=2\n",
    "#train_model(n_epochs, model, optimizer, loss_func, use_cuda,patience)\n",
    "#def train_model(n_epochs, model, optimizer, loss_func, use_cuda,patience):\n",
    "    \n",
    "        \n",
    "    # to track the training loss as the model trains\n",
    "    train_losses = []\n",
    "    # to track the validation loss as the model trains\n",
    "    valid_losses = []\n",
    "    # to track the average training loss per epoch as the model trains\n",
    "    avg_train_losses = []\n",
    "    # to track the average validation loss per epoch as the model trains\n",
    "    avg_valid_losses = []    \n",
    "    \n",
    "     # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True) \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        #train_losses = 0.0\n",
    "        #valid_losses = 0.0\n",
    "        \n",
    "        \n",
    "        # train the model #        \n",
    "        model.train()\n",
    "        for batch, (data, target) in enumerate(train_loader,1):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # initialize weights to zero\n",
    "            optimizer.zero_grad()            \n",
    "            output = model(data)            \n",
    "            # calculate loss\n",
    "            loss = loss_func(output, target)            \n",
    "            # back prop\n",
    "            loss.backward()            \n",
    "            # grad\n",
    "            optimizer.step()            \n",
    "            #train_losses = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_losses))\n",
    "            # record training loss\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            \"\"\"if batch_idx % 100 == 0:\"\"\"\n",
    "            #print('Epoch %d, Batch %d loss: %.6f' %(epoch, batch + 1, train_losses))        \n",
    "           \n",
    "        # validate the model\n",
    "        \n",
    "        model.eval()\n",
    "        for data, target in valid_loader:\n",
    "            # move to GPU\n",
    "            if torch.cuda.is_available():\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## update the average validation loss\n",
    "            output = model(data)\n",
    "            loss = loss_func(output, target)\n",
    "            #valid_losses = valid_losses + ((1 / (batch_idx + 1)) * (loss.data - valid_losses))\n",
    "            valid_losses.append(loss.item())            \n",
    "        \n",
    "        # print training/validation statistics \n",
    "       # calculate average loss over an epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "        epoch_len = len(str(n_epochs))\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch,train_loss,valid_loss ))\n",
    "        \n",
    "        # clear lists to track next epoch\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        \n",
    "        \n",
    "        # early_stopping needs the validation loss to check if it has decresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        early_stopping(valid_loss, model)        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break   \n",
    "            \n",
    "       \n",
    "            \n",
    "            \n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))      \n",
    "            \n",
    "    #return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'patience=20\\nn_epochs=2\\ntrain_model(n_epochs, model, optimizer, loss_func, use_cuda,patience)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"patience=20\n",
    "n_epochs=2\n",
    "train_model(n_epochs, model, optimizer, loss_func, use_cuda,patience)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3692916091901577\n",
      "Valid_Loss: 0.344699022139428\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Loss:\",train_loss)\n",
    "print(\"Valid_Loss:\",valid_loss)\n",
    "#print(ea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.plot(valid_loss, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5416c2251a5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# visualize the loss as the network trained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# visualize the loss as the network trained\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
    "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
    "\n",
    "# find position of lowest validation loss\n",
    "minposs = valid_loss.index(min(valid_loss))+1 \n",
    "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim(0, 0.5) # consistent scale\n",
    "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('loss_plot.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('malaria_detection.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_losses: 0.360145\n",
      "\n",
      "tensor(0.3601, device='cuda:0')\n",
      "\n",
      "Test Accuracy: 84% (2332/2756)\n"
     ]
    }
   ],
   "source": [
    "def test(model, loss_func, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_losses = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = loss_func(output, target)\n",
    "        # update average test loss \n",
    "        test_losses = test_losses + ((1 / (batch_idx + 1)) * (loss.data - test_losses))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test_losses: {:.6f}\\n'.format(test_losses))\n",
    "    print(test_losses)\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (100. * correct / total, correct, total))\n",
    "test(model, loss_func, use_cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the loss as the network trained\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
    "plt.plot(range(1,len(valid_losses)+1),valid_losses,label='Validation Loss')\n",
    "\n",
    "# find position of lowest validation loss\n",
    "minposs = valid_loss.index(min(valid_loss))+1 \n",
    "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim(0, 0.5) # consistent scale\n",
    "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('loss_plot.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_input_image(img_path):\n",
    "    image = Image.open(img_path)\n",
    "    \n",
    "    prediction_transform = transforms.Compose([transforms.Resize(size=(224, 224)),\n",
    "                                     transforms.ToTensor(), \n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                          [0.229, 0.224, 0.225])])\n",
    "\n",
    "    # discard the transparent, alpha channel (that's the :3) and add the batch dimension\n",
    "    image = prediction_transform(image)[:3,:,:].unsqueeze(0)\n",
    "    return image\n",
    "#load_input_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_malaria(model, class_names, img_path):\n",
    "    # load the image and return the predicted breed\n",
    "    img = load_input_image(img_path)\n",
    "    model = model.cpu()\n",
    "    model.eval()\n",
    "    idx = torch.argmax(model(img))\n",
    "    return class_names[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "from termcolor import colored\n",
    "\n",
    "inf = np.array(glob(\"../cell_images/Parasitized/*\"))\n",
    "uninf = np.array(glob(\"../cell_images/Uninfected/*\"))\n",
    "\n",
    "for i in range(3):\n",
    "    img_path=inf[i]\n",
    "    img = Image.open(img_path)\n",
    "    if predict_malaria(model, class_names, img_path) == 'Parasitized':\n",
    "        print(colored('Parasitized', 'green'))\n",
    "    else:\n",
    "        print(colored('Uninfected', 'red'))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "for i in range(3):\n",
    "    img_path=uninf[i]\n",
    "    img = Image.open(img_path)\n",
    "    if predict_malaria(model, class_names, img_path) == 'Uninfected':\n",
    "        print(colored('Uninfected', 'green'))\n",
    "    else:\n",
    "        print(colored('Parasitized', 'red'))        \n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
